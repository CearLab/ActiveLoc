{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import scipy.linalg as linalg\n",
    "import os\n",
    "import time\n",
    "from ParticleFilter import sample_normal_model, single_step_particle_filter, normal_model_pdf, single_step_particle_filter_measurement_window\n",
    "from utils.plotting import draw_ellipse, images_to_gif\n",
    "from utils.filesTools import get_exp_folder\n",
    "from utils.notionConnector import add_experiment_to_notion\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import ParticleFilter\n",
    "importlib.reload(ParticleFilter)\n",
    "from ParticleFilter import sample_normal_model, single_step_particle_filter, normal_model_pdf, single_step_particle_filter_measurement_window\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## setup params\n",
    "NUM_OF_BEACONS = 4\n",
    "NUM_OF_AGENTS = 1\n",
    "STATE_SIZE_2D = 2\n",
    "SINGLE_RANGE_MEASUREMENT_SIZE = 1\n",
    "RANGE_MEASUREMENT_SIZE = NUM_OF_BEACONS * SINGLE_RANGE_MEASUREMENT_SIZE * NUM_OF_AGENTS\n",
    "TOTAL_STATE_SIZE = NUM_OF_AGENTS * STATE_SIZE_2D + NUM_OF_BEACONS * STATE_SIZE_2D\n",
    "sigma_transition_agent = 0.5\n",
    "sigma_transition_beacon = 0.3\n",
    "sigma_measurement = 0.1\n",
    "stepsize = 2\n",
    "n_steps = 150\n",
    "n_particles = 100\n",
    "# model definition\n",
    "cov_measurement = np.diag([sigma_measurement**2 for i in range(RANGE_MEASUREMENT_SIZE)])\n",
    "cov_transition_agent = [sigma_transition_agent**2 for i in range(NUM_OF_AGENTS*STATE_SIZE_2D)]\n",
    "cov_transition_agent = [0 for i in range(NUM_OF_AGENTS*STATE_SIZE_2D)]\n",
    "cov_transition_beacon = [sigma_transition_beacon**2 for i in range(NUM_OF_BEACONS*STATE_SIZE_2D)]\n",
    "# cov_transition_beacon = [0 for i in range(NUM_OF_BEACONS*STATE_SIZE_2D)]\n",
    "# cov_transition_beacon[0:6] = [sigma_transition_beacon**2]*6\n",
    "cov_transition = np.diag(cov_transition_agent + cov_transition_beacon)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state manger\n",
    "get_agent_index = lambda i: slice(i*STATE_SIZE_2D, i*STATE_SIZE_2D + STATE_SIZE_2D)\n",
    "get_beacon_index = lambda i: slice(STATE_SIZE_2D*NUM_OF_AGENTS + i*STATE_SIZE_2D, STATE_SIZE_2D*NUM_OF_AGENTS + i*STATE_SIZE_2D + STATE_SIZE_2D)\n",
    "get_agent_position = lambda x, i: x[get_agent_index(i)]\n",
    "get_beacon_postion = lambda x, j: x[get_beacon_index(j)]\n",
    "def state_to_agent_and_beacons_pos(x):\n",
    "    agents_pos = np.zeros((NUM_OF_AGENTS, STATE_SIZE_2D))\n",
    "    beacons_pos = np.zeros((NUM_OF_BEACONS, STATE_SIZE_2D))\n",
    "    for i in range(NUM_OF_AGENTS):\n",
    "        agents_pos[i] = get_agent_position(x, i)\n",
    "    for j in range(NUM_OF_BEACONS):\n",
    "        beacons_pos[j] = get_beacon_postion(x, j)\n",
    "    return agents_pos, beacons_pos\n",
    "def agent_and_beacons_pos_to_state(agents_pos, beacons_pos):\n",
    "    x = np.zeros(TOTAL_STATE_SIZE)\n",
    "    for i in range(NUM_OF_AGENTS):\n",
    "        x[get_agent_index(i)] = agents_pos[i]\n",
    "    for j in range(NUM_OF_BEACONS):\n",
    "        x[get_beacon_index(j)] = beacons_pos[j]\n",
    "    return x\n",
    "## model definition\n",
    "'''\n",
    "Function to propagate the state based on the control input and a normal model\n",
    "'''\n",
    "propagate_state_function = lambda x, u: x + sample_normal_model(u, cov_transition)\n",
    "\n",
    "\n",
    "def calculate_true_range_meas(x):\n",
    "    \"\"\"\n",
    "    Function to calculate the true range measurements.\n",
    "    It calculates the Euclidean distance between each agent and each beacon.\n",
    "    \"\"\"\n",
    "    z = np.zeros(RANGE_MEASUREMENT_SIZE)\n",
    "    for i in range(NUM_OF_AGENTS):\n",
    "        current_agent_position = x[get_agent_index(i)]\n",
    "        for j in range(NUM_OF_BEACONS):\n",
    "            current_beacon_position = x[get_beacon_index(j)]\n",
    "            z[i*NUM_OF_BEACONS + j] = np.linalg.norm(current_agent_position - current_beacon_position)\n",
    "    return z\n",
    "\n",
    "def measurements_model(x, cov = cov_measurement):\n",
    "    '''\n",
    "    Function to generate the range measurements model.\n",
    "    It adds a normally distributed noise to the true range measurements.\n",
    "    '''\n",
    "    return calculate_true_range_meas(x) + sample_normal_model(np.zeros(RANGE_MEASUREMENT_SIZE), cov)\n",
    "\n",
    "'''\n",
    "function to calculates the likelihood of the measurements given the state.\n",
    "It uses a normal probability density function with the true range measurements\n",
    "as the mean and the measurement covariance as the covariance\n",
    "'''\n",
    "measurements_likelihood = lambda z, x: normal_model_pdf(z, calculate_true_range_meas(x), cov_measurement)\n",
    "## test models and conversion functions\n",
    "if 0:\n",
    "    x = np.array([0, 0, 1, 0, 2, 0, 3, 0, 4, 0])*100\n",
    "    u = np.zeros(TOTAL_STATE_SIZE)\n",
    "    print(measurements_model(x))\n",
    "    print(propagate_state_function(x, u))\n",
    "## test conversion functions\n",
    "if 0:\n",
    "    x = np.array([0, 0, 1, 1, 2, 2, 3, 3, 4, 4])\n",
    "    agents_pos, beacons_pos = state_to_agent_and_beacons_pos(x)\n",
    "    print(agents_pos, beacons_pos)\n",
    "    print(agent_and_beacons_pos_to_state(agents_pos, beacons_pos))\n",
    "# pf Utils functions\n",
    "def draw_frame(x,particles,frames_folder,i,ellipse = True):\n",
    "    colors = ['r', 'g', 'b', 'y', 'm']\n",
    "    fig, ax = plt.subplots()\n",
    "    for j in range(NUM_OF_AGENTS):\n",
    "        agent_gt_pos = x[get_agent_index(j),i]\n",
    "        agent_particles = particles[:,get_agent_index(j)]\n",
    "        agent_color = colors[j]\n",
    "        ax.scatter(agent_gt_pos[0], agent_gt_pos[1], color = agent_color)\n",
    "        if ellipse:\n",
    "            draw_ellipse(ax, edgecolor = agent_color ,data = agent_particles)\n",
    "        else:\n",
    "            ax.scatter(agent_particles[:,0], agent_particles[:,1], c = agent_color, marker = 'x')\n",
    "            \n",
    "    for j in range(NUM_OF_BEACONS):\n",
    "        beacon_gt_pos = x[get_beacon_index(j),i]\n",
    "        beacon_particles = particles[:,get_beacon_index(j)]\n",
    "        beacon_color = colors[j+NUM_OF_AGENTS]\n",
    "        ax.scatter(beacon_gt_pos[0], beacon_gt_pos[1], color = beacon_color)\n",
    "        if ellipse:\n",
    "            draw_ellipse(ax, edgecolor= beacon_color ,data = beacon_particles)\n",
    "        else:\n",
    "            ax.scatter(beacon_particles[:,0], beacon_particles[:,1], c = beacon_color, marker = 'x')\n",
    "    \n",
    "    plt.xlim(-20, 20)\n",
    "    plt.ylim(-20, 20)\n",
    "    plt.title(f'frame {i}')\n",
    "    plt.savefig(f'{frames_folder}/frame_{i}.png')\n",
    "    plt.close()\n",
    "    \n",
    "def calculate_mean_and_cov(particles):\n",
    "    mean = np.mean(particles, axis = 0)\n",
    "    cov = np.cov(particles.T).flatten()\n",
    "    return mean, cov\n",
    "\n",
    "def save_ground_truth(x, z, exp_folder):\n",
    "    pd.DataFrame(x).to_csv(f'{exp_folder}/ground_truth_state.csv')\n",
    "    pd.DataFrame(z).to_csv(f'{exp_folder}/ground_truth_measurement.csv')\n",
    "\n",
    "def save_current_particles(particles, exp_folder, i):\n",
    "    if not os.path.exists(exp_folder):\n",
    "        os.makedirs(exp_folder)\n",
    "    if not os.path.exists(f'{exp_folder}/particles'):\n",
    "        os.makedirs(f'{exp_folder}/particles')\n",
    "    pd.DataFrame(particles).to_csv(f'{exp_folder}/particles/particles_{i}.csv')\n",
    "\n",
    "def run_particle_filter_experiment(note, particles, n_steps, total_state_size, x, u, z, propagate_state_function, measurements_likelihood_function, resample_method='systematic', save_particles=False, ellipse=True):\n",
    "    exp_folder, frames_folder = get_exp_folder(note = note)\n",
    "    mean_log = np.zeros((n_steps, total_state_size))\n",
    "    cov_log = np.zeros((n_steps, total_state_size**2))\n",
    "\n",
    "    for i in range(n_steps):\n",
    "        if 1:\n",
    "            draw_frame(x, particles, frames_folder, i, ellipse = ellipse)\n",
    "        if save_particles:\n",
    "            save_current_particles(particles, exp_folder, i)\n",
    "        \n",
    "        particles = single_step_particle_filter(particles, u[:,i], z[:,i], propagate_state_function, measurements_likelihood_function, resample_method = resample_method)\n",
    "        mean_log[i], cov_log[i] = calculate_mean_and_cov(particles)\n",
    "        print(f\"\\r{i}/{n_steps}\", end='', flush=True)\n",
    "    print('\\n')\n",
    "    if 1:\n",
    "        draw_frame(x, particles, frames_folder, i = n_steps - 1, ellipse = ellipse)\n",
    "    if save_particles:\n",
    "        save_current_particles(particles, exp_folder, i)\n",
    "    images_to_gif(frames_folder, f'{exp_folder}/particle_filter.gif')\n",
    "    pd.DataFrame(mean_log).to_csv(f'{exp_folder}/mean_log.csv', index = False, header = False)\n",
    "    pd.DataFrame(cov_log).to_csv(f'{exp_folder}/cov_log.csv', index = False, header = False)\n",
    "    save_ground_truth(x, z, exp_folder)\n",
    "    try:\n",
    "        path_ = Path(exp_folder)\n",
    "        folder_name = path_.name\n",
    "        exp_data = {\"Name\": folder_name, \"folder path\": exp_folder}\n",
    "        add_experiment_to_notion(exp_data)\n",
    "    except:\n",
    "        print('Failed to add experiment to notion')\n",
    "    return mean_log, cov_log, exp_folder, particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## generate ground truth\n",
    "agent_position_0 = np.array([0,0])\n",
    "becons_1_position_0 = np.array([10,10])\n",
    "becons_2_position_0 = np.array([-10,10])\n",
    "becons_3_position_0 = np.array([10,-10])\n",
    "becons_4_position_0 = np.array([-10,-10])\n",
    "x_0 = agent_and_beacons_pos_to_state([agent_position_0], [becons_1_position_0, becons_2_position_0, becons_3_position_0, becons_4_position_0])\n",
    "\n",
    "#genrate u  commend vector\n",
    "u = (np.random.rand(TOTAL_STATE_SIZE, n_steps) - 0.5) * stepsize\n",
    "u = np.zeros((TOTAL_STATE_SIZE, n_steps))\n",
    "u[get_agent_index(0),:] = (np.random.rand(STATE_SIZE_2D, n_steps) - 0.5) * stepsize\n",
    "u[get_beacon_index(0),:] = (np.random.rand(STATE_SIZE_2D, n_steps) - 0.5) * stepsize/10\n",
    "u[get_beacon_index(1),:] = (np.random.rand(STATE_SIZE_2D, n_steps) - 0.5) * stepsize/10\n",
    "u[get_beacon_index(2),:] = (np.random.rand(STATE_SIZE_2D, n_steps) - 0.5) * stepsize/10\n",
    "u[get_beacon_index(3),:] = (np.random.rand(STATE_SIZE_2D, n_steps) - 0.5) * stepsize/10\n",
    "## create ground truth\n",
    "x = np.zeros((TOTAL_STATE_SIZE, n_steps))\n",
    "x[:,0] = x_0\n",
    "z = np.zeros((RANGE_MEASUREMENT_SIZE, n_steps))\n",
    "z[:,0] = measurements_model(x[:,0])\n",
    "for i in range(1, n_steps):\n",
    "    x[:,i] = propagate_state_function(x[:,i-1], u[:,i-1])\n",
    "    z[:,i] = measurements_model(x[:,i])\n",
    "\n",
    "## plot ground truth\n",
    "if 0:\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(x[0,:], x[1,:], 'r')\n",
    "    ax.plot(x[2,:], x[3,:], 'g')\n",
    "    ax.plot(x[4,:], x[5,:], 'b')\n",
    "    ax.plot(x[6,:], x[7,:], 'y')\n",
    "    ax.plot(x[8,:], x[9,:], 'm')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVE_EACH_FRAME = 0\n",
    "n_particles = 1000\n",
    "particles = (np.random.rand(n_particles, TOTAL_STATE_SIZE) - 0.5) * 15\n",
    "particles[:,get_agent_index(0)] = np.zeros((n_particles, STATE_SIZE_2D))\n",
    "r = np.linalg.norm(becons_1_position_0)\n",
    "theta = np.linspace(0, 2*np.pi, n_particles)\n",
    "beacons_pos_0 = np.array([r*np.cos(theta), r*np.sin(theta)]).T\n",
    "particles[:,get_beacon_index(0)] = beacons_pos_0\n",
    "particles[:,get_beacon_index(1)] = beacons_pos_0\n",
    "particles[:,get_beacon_index(2)] = beacons_pos_0\n",
    "particles[:,get_beacon_index(3)] = beacons_pos_0\n",
    "particles_zero = particles.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "101/150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idosh\\Repos\\ActiveLoc\\PF\\ParticleFilter.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  return weights/np.sum(weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/150\n",
      "\n",
      "gif saved to results\\20240517\\exp_20240517_094143_circle initialization - systematic resampling/particle_filter.gif\n"
     ]
    }
   ],
   "source": [
    "## systematic\n",
    "NOTE = 'circle initialization - systematic resampling'\n",
    "\n",
    "systematic_output = run_particle_filter_experiment(note = NOTE,\n",
    "                                                    n_steps= n_steps,\n",
    "                                                    particles = particles_zero,\n",
    "                                                    total_state_size = TOTAL_STATE_SIZE,\n",
    "                                                    x = x,\n",
    "                                                    u = u,\n",
    "                                                    z = z,\n",
    "                                                    propagate_state_function=propagate_state_function,\n",
    "                                                    measurements_likelihood_function = measurements_likelihood,\n",
    "                                                    resample_method='systematic',\n",
    "                                                    save_particles=SAVE_EACH_FRAME,\n",
    "                                                    ellipse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/150\n",
      "\n",
      "gif saved to results\\20240517\\exp_20240517_094256_circle initialization - stratified resampling/particle_filter.gif\n"
     ]
    }
   ],
   "source": [
    "## stratified\n",
    "NOTE = 'circle initialization - stratified resampling'\n",
    "stratified_output = run_particle_filter_experiment(note = NOTE,\n",
    "                                                    n_steps= n_steps,\n",
    "                                                    particles = particles_zero,\n",
    "                                                    total_state_size = TOTAL_STATE_SIZE,\n",
    "                                                    x = x,\n",
    "                                                    u = u,\n",
    "                                                    z = z,\n",
    "                                                    propagate_state_function=propagate_state_function,\n",
    "                                                    measurements_likelihood_function = measurements_likelihood,\n",
    "                                                    resample_method='stratified',\n",
    "                                                    save_particles=SAVE_EACH_FRAME,\n",
    "                                                    ellipse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/150\n",
      "\n",
      "gif saved to results\\20240517\\exp_20240517_094408_circle initialization - multinomial resampling/particle_filter.gif\n"
     ]
    }
   ],
   "source": [
    "## multinomial\n",
    "NOTE = 'circle initialization - multinomial resampling'\n",
    "\n",
    "multinomial_output = run_particle_filter_experiment(note = NOTE,\n",
    "                                                    n_steps= n_steps,\n",
    "                                                    particles = particles_zero,\n",
    "                                                    total_state_size = TOTAL_STATE_SIZE,\n",
    "                                                    x = x,\n",
    "                                                    u = u,\n",
    "                                                    z = z,\n",
    "                                                    propagate_state_function=propagate_state_function,\n",
    "                                                    measurements_likelihood_function = measurements_likelihood,\n",
    "                                                    resample_method='multinomial',\n",
    "                                                    save_particles=SAVE_EACH_FRAME,\n",
    "                                                    ellipse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/150"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\idosh\\Repos\\ActiveLoc\\PF\\ParticleFilter.py:33: RuntimeWarning: invalid value encountered in divide\n",
      "  return weights/np.sum(weights)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149/150\n",
      "\n",
      "gif saved to results\\20240517\\exp_20240517_095022_circle initialization - none resampling/particle_filter.gif\n"
     ]
    }
   ],
   "source": [
    "## none\n",
    "NOTE = 'circle initialization - none resampling'\n",
    "none_output = run_particle_filter_experiment(note = NOTE,\n",
    "                                                    n_steps= n_steps,\n",
    "                                                    particles = particles_zero,\n",
    "                                                    total_state_size = TOTAL_STATE_SIZE,\n",
    "                                                    x = x,\n",
    "                                                    u = u,\n",
    "                                                    z = z,\n",
    "                                                    propagate_state_function=propagate_state_function,\n",
    "                                                    measurements_likelihood_function = measurements_likelihood,\n",
    "                                                    resample_method='none',\n",
    "                                                    save_particles=SAVE_EACH_FRAME,\n",
    "                                                    ellipse=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combain all outputs to one gif\n",
    "systematic_folder = os.path.join(systematic_output[2], 'frames')\n",
    "stratified_folder = os.path.join(stratified_output[2], 'frames')\n",
    "multinomial_folder = os.path.join(multinomial_output[2], 'frames')\n",
    "none_folder = os.path.join(none_output[2], 'frames')\n",
    "output_folder = os.path.join('results', 'all_resampling_methods_compare')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "os.makedirs(os.path.join(output_folder, 'frames'), exist_ok=True)\n",
    "\n",
    "# For each frame, load all the four images and combine them into one image\n",
    "for i in range(n_steps):\n",
    "    systematic_img = plt.imread(f'{systematic_folder}/frame_{i}.png')\n",
    "    stratified_img = plt.imread(f'{stratified_folder}/frame_{i}.png')\n",
    "    multinomial_img = plt.imread(f'{multinomial_folder}/frame_{i}.png')\n",
    "    none_img = plt.imread(f'{none_folder}/frame_{i}.png')\n",
    "\n",
    "    # Combine all images into one image in 2 rows and 2 columns\n",
    "    combined_img = np.zeros((systematic_img.shape[0]*2, systematic_img.shape[1]*2, 3))\n",
    "    combined_img[0:systematic_img.shape[0], 0:systematic_img.shape[1]] = systematic_img[:, :, :3]\n",
    "    combined_img[0:systematic_img.shape[0], systematic_img.shape[1]:] = stratified_img[:, :, :3]\n",
    "    combined_img[systematic_img.shape[0]:, 0:systematic_img.shape[1]] = multinomial_img[:, :, :3]\n",
    "    combined_img[systematic_img.shape[0]:, systematic_img.shape[1]:] = none_img[:, :, :3]\n",
    "\n",
    "    # Create a figure\n",
    "    plt.figure(figsize=(10, 10))\n",
    "    plt.imshow(combined_img)\n",
    "    plt.axis('off')  # Hide axes\n",
    "\n",
    "    # Add titles to each image\n",
    "    plt.text(0, 0, 'systematic', color='white', backgroundcolor='black', fontsize=12, ha='left', va='top')\n",
    "    plt.text(systematic_img.shape[1], 0, 'stratified', color='white', backgroundcolor='black', fontsize=12, ha='left', va='top')\n",
    "    plt.text(0, systematic_img.shape[0], 'multinomial', color='white', backgroundcolor='black', fontsize=12, ha='left', va='top')\n",
    "    plt.text(systematic_img.shape[1], systematic_img.shape[0], 'none', color='white', backgroundcolor='black', fontsize=12, ha='left', va='top')\n",
    "\n",
    "    # Save the combined image\n",
    "    plt.savefig(f'{output_folder}/frames/frame_{i}.png', bbox_inches='tight', pad_inches=0)\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gif saved to results\\all_resampling_methods_compare/all_resampling_methods_compare.gif\n"
     ]
    }
   ],
   "source": [
    "## join it to gif\n",
    "images_to_gif(f'{output_folder}/frames', f'{output_folder}/all_resampling_methods_compare.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calc errors\n",
    "if 0:\n",
    "    errors = np.zeros((n_steps, TOTAL_STATE_SIZE))\n",
    "    for i in range(n_steps):\n",
    "        errors[i] = x[:,i] - mean_log[i]\n",
    "    pd.DataFrame(errors).to_csv(f'{exp_folder}/errors.csv', index = False, header = False)\n",
    "\n",
    "    #plot errors, split by aagent and beacons in different subplots for each agent and beacon\n",
    "    if 1:\n",
    "        fig, axs = plt.subplots(NUM_OF_AGENTS + NUM_OF_BEACONS, 1)\n",
    "        for i in range(NUM_OF_AGENTS):\n",
    "            axs[i].plot(np.linalg.norm(errors[:,get_agent_index(i)],axis = 1))\n",
    "            axs[i].set_title(f'agent {i} errors')\n",
    "        for j in range(NUM_OF_BEACONS):\n",
    "            axs[NUM_OF_AGENTS + j].plot(np.linalg.norm(errors[:,get_beacon_index(j)],axis = 1))\n",
    "            axs[NUM_OF_AGENTS + j].set_title(f'beacon {j} errors')\n",
    "        plt.show()\n",
    "        \n",
    "    # plot the measermnt resedules\n",
    "    meas_residual = np.zeros((n_steps, RANGE_MEASUREMENT_SIZE))\n",
    "    for i in range(n_steps):\n",
    "        meas_residual[i] = calculate_true_range_meas(mean_log[i]) - calculate_true_range_meas(x[:,i])\n",
    "    if 1:\n",
    "        fig, axs = plt.subplots(RANGE_MEASUREMENT_SIZE, 1)\n",
    "        for i in range(RANGE_MEASUREMENT_SIZE):\n",
    "            axs[i].plot(meas_residual[:,i])\n",
    "            axs[i].set_title(f'measurement {i} residuals')\n",
    "        plt.show()\n",
    "    # put state error and meas error in the same subplots\n",
    "    if 1:\n",
    "        fig, axs = plt.subplots(NUM_OF_BEACONS, 1)\n",
    "        for i in range(NUM_OF_BEACONS):\n",
    "            axs[i].plot(np.linalg.norm(errors[:,get_beacon_index(i)],axis = 1))\n",
    "            axs[i].plot(meas_residual[:,i])\n",
    "            # axs[i].set_title(f'state {i} errors')\n",
    "        plt.legend(['state error', 'meas error'])\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
